{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f464d1-edf3-4e3d-a3d4-71349d81f8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\tarik\\Anaconda3\\envs\\graphs\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "from Embed import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d482ccec-db1f-4543-9916-12adbf7c5fb1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c868572e-feba-4da0-9f60-fb78e0f3c152",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " reading part 1 \n",
      " graph of     180366 node        and 385592  edge\n",
      "matrix shape :  180366 X 180366\n",
      "   matrix is normalized         \n",
      "   matrix of transaction built       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                       | 0/385592 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 385592   edges in current level ' 2 '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 385592/385592 [11:31<00:00, 557.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 2 built  in 692.2100548744202\n",
      "   begin embedding         \n",
      "Embeding done in  762.9900488853455\n",
      "180366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n    # --------------- test ------------------------------------\\n    #test_graph_name = 'graphs/graph_test_' + str(ix) + '.gml.gz'\\n    test_edges_name = '../../graphs/graph_test_edges_sampled_' + str(ix) + '.csv'\\n\\n    if 'adar' in method_:\\n        list_pred_scores_test, list_real_labels_test = collectAdarScores(G, test_edges_name)\\n    else:\\n        list_pred_scores_test, list_real_labels_test = collectJaccardScores(G, test_edges_name)\\n    list_pred_labels_test = classifyFeatures(np.array(list_pred_scores_test).reshape(-1, 1), model)\\n\\n    fo__ = open('prediction_results_test_mp_' + str(ix) + '.txt', 'w')\\n    for icurrpred in range(len(list_pred_labels_test)):\\n        fo__.write(str(list_pred_labels_test[icurrpred, 1]) + '\\t' + str(list_real_labels_test[icurrpred]) + '\\n')\\n    fo__.close()\\n    # compute the performance over test set\\n    tp_t, tn_t, fp_t, fn_t = computeAccuracy(list_pred_labels_test[:, 1], list_real_labels_test)\\n    acc_t = (tp_t+tn_t)/float(tp_t+tn_t+fp_t+fn_t)\\n    fo.write('test\\t' + str(tp_t) + '\\t' + str(tn_t) + '\\t' + str(fp_t) + '\\t' + str(fn_t) + '\\t' + str(acc_t) + '\\n')\\n    del G\\n\\nfo.close()\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo = open('accuracy_test_results_baseline_mp.txt', 'w')\n",
    "fo.write('set\\ttp\\ttn\\tfp\\tfn\\tacc\\n')\n",
    "# read the A_train graph\n",
    "for ix in range(1, 2):#range(1, 6)\n",
    "\n",
    "    # ---------------- training ----------------------\n",
    "    train_graph_name = '../../graphs/graph_sampled_' + str(ix) + '.gml.gz'\n",
    "    G = nx.read_gml(train_graph_name)\n",
    "    print (f\" reading part {str(ix)} \\n graph of     {len(G.nodes())} node        and {len(G.edges())}  edge\")\n",
    "    #train_edges_name = '../../graphs/graph_train_edges_sampled_' + str(ix) + '.csv'\n",
    "\n",
    "    x_data = nodes_embedding(G,2,0.9)\n",
    "    DD = []\n",
    "    for i in x_data.values():\n",
    "        dic = {}\n",
    "        items = []\n",
    "        for k,v in i.items():\n",
    "            items.append(k)\n",
    "            dic[len(items)-1] = float(v)\n",
    "        #dic = sorted(dic)\n",
    "        #dic = dict(collections.OrderedDict(sorted(dic.items())))\n",
    "        #print(dic)\n",
    "        DD.append(dic)\n",
    "    print(len(DD[0]))\n",
    "    embd = []\n",
    "    for i in range(len(items)):\n",
    "        embd.append([DD[0][i],DD[1][i]])#,DD[2][i]])#,DD[3][i],DD[4][i],DD[5][i],DD[6][i]])\n",
    "    #df = pd.DataFrame(embd)\n",
    "    #file = f\"./ebd{ix}.csv\"\n",
    "    df = pd.DataFrame(items)\n",
    "    file = f\"./items.csv\"\n",
    "    df.to_csv(file)\n",
    "    del G\n",
    "    del x_data\n",
    "    \n",
    "    # --------------- validation ---------------------------\n",
    "    #val_edges_name = '../../graphs/graph_val_edges_sampled_' + str(ix) + '.csv'\n",
    "\n",
    "    # compute the performance over validation set\n",
    "    #list_pred_scores_val, list_real_labels_val = collectAdarScores(G, val_edges_name)\n",
    "\n",
    "    # train and fit the deep learning model np.array(list_pred_scores).reshape(-1, 1)\n",
    "    #model = trainTheClassifier(np.array(list_pred_scores_train).reshape(-1, 1), list_real_labels_train, np.array(list_pred_scores_val).reshape(-1, 1), list_real_labels_val)\n",
    "'''\n",
    "    # --------------- test ------------------------------------\n",
    "    #test_graph_name = 'graphs/graph_test_' + str(ix) + '.gml.gz'\n",
    "    test_edges_name = '../../graphs/graph_test_edges_sampled_' + str(ix) + '.csv'\n",
    "\n",
    "    if 'adar' in method_:\n",
    "        list_pred_scores_test, list_real_labels_test = collectAdarScores(G, test_edges_name)\n",
    "    else:\n",
    "        list_pred_scores_test, list_real_labels_test = collectJaccardScores(G, test_edges_name)\n",
    "    list_pred_labels_test = classifyFeatures(np.array(list_pred_scores_test).reshape(-1, 1), model)\n",
    "\n",
    "    fo__ = open('prediction_results_test_mp_' + str(ix) + '.txt', 'w')\n",
    "    for icurrpred in range(len(list_pred_labels_test)):\n",
    "        fo__.write(str(list_pred_labels_test[icurrpred, 1]) + '\\t' + str(list_real_labels_test[icurrpred]) + '\\n')\n",
    "    fo__.close()\n",
    "    # compute the performance over test set\n",
    "    tp_t, tn_t, fp_t, fn_t = computeAccuracy(list_pred_labels_test[:, 1], list_real_labels_test)\n",
    "    acc_t = (tp_t+tn_t)/float(tp_t+tn_t+fp_t+fn_t)\n",
    "    fo.write('test\\t' + str(tp_t) + '\\t' + str(tn_t) + '\\t' + str(fp_t) + '\\t' + str(fn_t) + '\\t' + str(acc_t) + '\\n')\n",
    "    del G\n",
    "\n",
    "fo.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cc5438d-321a-4cea-8b25-1d9d8476a7e6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-4ddd2a84f133>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mDD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_data' is not defined"
     ]
    }
   ],
   "source": [
    "DD = []\n",
    "for i in x_data.values():\n",
    "    dic = {}\n",
    "    items = []\n",
    "    for k,v in i.items():\n",
    "        items.append(k)\n",
    "        dic[len(items)-1] = float(v)\n",
    "    #dic = sorted(dic)\n",
    "    #dic = dict(collections.OrderedDict(sorted(dic.items())))\n",
    "    #print(dic)\n",
    "    DD.append(dic)\n",
    "print(len(DD[0]))\n",
    "embd = []\n",
    "for i in range(len(items)):\n",
    "    embd.append([DD[0][i],DD[1][i]])#,DD[2][i]])#,DD[3][i],DD[4][i],DD[5][i],DD[6][i]])\n",
    "df = pd.DataFrame(embd)\n",
    "file = f\"./embed{ix}.csv\"\n",
    "df.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2ef6e6e-7223-47b7-b9bb-559d95077c35",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['take', 'taskforce', 'america', 'game', 'speak', 'exceptional adulthood']\n"
     ]
    }
   ],
   "source": [
    "print(list(x_data[1].keys())[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d752cdd7-de6b-42f3-a421-c1074696b574",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.002961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1\n",
       "0           0  0.003640  0.002961\n",
       "1           1  0.000045  0.000039\n",
       "2           2  0.000116  0.000094\n",
       "3           3  0.000689  0.000550\n",
       "4           4  0.000313  0.000245"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('embed1.csv') \n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56378a46-3a45-45a9-b565-62f12be78cd9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " reading part 1 \n",
      " graph of     180366 node        and 385592  edge\n",
      "matrix shape :  180366 X 180366\n",
      "   matrix is normalized         \n",
      "   matrix of transaction built       \n",
      "   begin embedding         \n",
      "Embeding done in  14.083883285522461\n",
      "180366\n",
      " reading part 2 \n",
      " graph of     180366 node        and 385592  edge\n",
      "matrix shape :  180366 X 180366\n",
      "   matrix is normalized         \n",
      "   matrix of transaction built       \n",
      "   begin embedding         \n",
      "Embeding done in  17.68531370162964\n",
      "180366\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b1df117d0738>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# ---------------- training ----------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_graph_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../../graphs/graph_sampled_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.gml.gz'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_gml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_graph_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34mf\" reading part {str(ix)} \\n graph of     {len(G.nodes())} node        and {len(G.edges())}  edge\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#train_edges_name = '../../graphs/graph_train_edges_sampled_' + str(ix) + '.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-735>\u001b[0m in \u001b[0;36mread_gml\u001b[1;34m(path, label, destringizer)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphs\\lib\\site-packages\\networkx\\utils\\decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(func_to_be_decorated, *args, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;31m# Finally, we call the original function, making sure to close the fobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_to_be_decorated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclose_fobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphs\\lib\\site-packages\\networkx\\readwrite\\gml.py\u001b[0m in \u001b[0;36mread_gml\u001b[1;34m(path, label, destringizer)\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m     \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_gml_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestringizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphs\\lib\\site-packages\\networkx\\readwrite\\gml.py\u001b[0m in \u001b[0;36mparse_gml_lines\u001b[1;34m(lines, label, destringizer)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[0mdirected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'directed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphs\\lib\\site-packages\\networkx\\readwrite\\gml.py\u001b[0m in \u001b[0;36mparse_graph\u001b[1;34m()\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparse_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m         \u001b[0mcurr_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_kv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcurr_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# EOF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[0munexpected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'EOF'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphs\\lib\\site-packages\\networkx\\readwrite\\gml.py\u001b[0m in \u001b[0;36mparse_kv\u001b[1;34m(curr_token)\u001b[0m\n\u001b[0;32m    370\u001b[0m                 \u001b[0mcurr_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mcategory\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# dict start\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m                 \u001b[0mcurr_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m                 \u001b[0munexpected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"an int, float, string or '['\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphs\\lib\\site-packages\\networkx\\readwrite\\gml.py\u001b[0m in \u001b[0;36mparse_dict\u001b[1;34m(curr_token)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparse_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mcurr_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconsume\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"'['\"\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# dict start\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0mcurr_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_kv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[0mcurr_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconsume\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"']'\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# dict end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcurr_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdct\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphs\\lib\\site-packages\\networkx\\readwrite\\gml.py\u001b[0m in \u001b[0;36mparse_kv\u001b[1;34m(curr_token)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mcurr_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurr_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m             \u001b[0mcurr_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m             \u001b[0mcategory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurr_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcategory\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# reals or ints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphs\\lib\\site-packages\\networkx\\readwrite\\gml.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m()\u001b[0m\n\u001b[0;32m    319\u001b[0m                 \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m                         \u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "items = []\n",
    "for ix in range(1, 6):#range(1, 6)\n",
    "\n",
    "    # ---------------- training ----------------------\n",
    "    train_graph_name = '../../graphs/graph_sampled_' + str(ix) + '.gml.gz'\n",
    "    G = nx.read_gml(train_graph_name)\n",
    "    print (f\" reading part {str(ix)} \\n graph of     {len(G.nodes())} node        and {len(G.edges())}  edge\")\n",
    "    #train_edges_name = '../../graphs/graph_train_edges_sampled_' + str(ix) + '.csv'\n",
    "\n",
    "    x_data = nodes_embedding(G,1,0.9)\n",
    "    DD = []\n",
    "    for i in x_data.values():\n",
    "        dic = {}\n",
    "        item = []\n",
    "        for k,v in i.items():\n",
    "            item.append(k)\n",
    "            dic[len(item)-1] = float(v)\n",
    "        #dic = sorted(dic)\n",
    "        #dic = dict(collections.OrderedDict(sorted(dic.items())))\n",
    "        #print(dic)\n",
    "        DD.append(dic)\n",
    "    print(len(DD[0]))\n",
    "    embd = []\n",
    "    for i in range(len(item)):\n",
    "        embd.append([DD[0][i]])#,DD[1][i]])#,DD[2][i]])#,DD[3][i],DD[4][i],DD[5][i],DD[6][i]])\n",
    "    df = pd.DataFrame(embd)\n",
    "    file = f\"./emb{ix}.csv\"\n",
    "    #df.to_csv(file)\n",
    "    items.append(item)\n",
    "    del G\n",
    "    del x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc244e78-18c6-4694-8948-7aeb75c162ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph_name = '../../graphs/graph_sampled_1.gml.gz'\n",
    "G = nx.read_gml(train_graph_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b06752f-cb74-4244-9dc6-67d7108737cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 385592/385592 [00:00<00:00, 807088.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>take</td>\n",
       "      <td>poverty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>take</td>\n",
       "      <td>laboratory station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>take</td>\n",
       "      <td>drug database</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>take</td>\n",
       "      <td>docking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take</td>\n",
       "      <td>benazepril</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  node_1              node_2\n",
       "0   take             poverty\n",
       "1   take  laboratory station\n",
       "2   take       drug database\n",
       "3   take             docking\n",
       "4   take          benazepril"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_list_1 = []\n",
    "node_list_2 = []\n",
    "\n",
    "for i in tqdm(G.edges()):\n",
    "    #print(i)\n",
    "    node_list_1.append(i[0])\n",
    "    node_list_2.append(i[1])\n",
    "\n",
    "G_df = pd.DataFrame({'node_1': node_list_1, 'node_2': node_list_2})\n",
    "\n",
    "G_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2150267-4915-47c4-ae8c-34cba36c4c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all nodes in a list\n",
    "node_list = node_list_1 + node_list_2\n",
    "\n",
    "# remove duplicate items from the list\n",
    "node_list = list(dict.fromkeys(node_list))\n",
    "\n",
    "# build adjacency matrix\n",
    "M = adjacency_matrix(G,nodelist=G.nodes())\n",
    "#adj_G = nx.to_numpy_matrix(G, nodelist = node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cac74a8-8c94-4def-8281-f4e5a468e265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "networkx.classes.reportviews.NodeView"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c978819-9ed3-4c42-b9a2-1e562a2c7bb0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                       | 0/180366 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1739147582e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m#if i != j:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mall_unconnected_pairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0moffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moffset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'items' is not defined"
     ]
    }
   ],
   "source": [
    "all_unconnected_pairs = []\n",
    "\n",
    "\n",
    "offset = 0\n",
    "M = M.tolil()\n",
    "for i in tqdm(range(M.shape[0])):\n",
    "    for j in range(offset,M.shape[1]):\n",
    "        #print(M[i,j])\n",
    "        #if i != j:\n",
    "        if M[i,j] == 0:\n",
    "            all_unconnected_pairs.append([items[0][i],items[0][j]])\n",
    "    offset = offset + 1\n",
    "\n",
    "'''\n",
    "            if nx.has_path(G, items[0][i], items[0][j]):\n",
    "                #if nx.shortest_path(G, items[0][i], items[0][j]):\n",
    "                if nx.shortest_path_length(G, items[0][i], items[0][j]) <=2:\n",
    "                    if M[i,j] == 0:\n",
    "                        all_unconnected_pairs.append([items[0][i],items[0][j]])\n",
    "\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0fed447-1396-47d5-8380-ba2e3aa05977",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edges_name = '../../graphs/graph_train_edges_sampled_1.csv'\n",
    "df_train = pd.read_csv(train_edges_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c0a97a-e1ac-4d62-8fcb-eea2a84693f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item = pd.read_csv('items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7efd6f5b-a5ae-4985-89cd-095a96b49b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>taskforce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>america</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>speak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          0\n",
       "0           0       take\n",
       "1           1  taskforce\n",
       "2           2    america\n",
       "3           3       game\n",
       "4           4      speak"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1268634c-b61b-4824-87c7-c38b0ad585c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>concept</td>\n",
       "      <td>sewage-based epidemiology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tissue</td>\n",
       "      <td>adaptive immunity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>advance</td>\n",
       "      <td>sequencing technology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>overtrained state</td>\n",
       "      <td>dynamic complex system</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>self-assembly review</td>\n",
       "      <td>wet condition</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 node1                      node2  labels\n",
       "0           0               concept  sewage-based epidemiology       1\n",
       "1           1                tissue          adaptive immunity       1\n",
       "2           2               advance      sequencing technology       1\n",
       "3           3     overtrained state     dynamic complex system       0\n",
       "4           4  self-assembly review              wet condition       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca065b23-407f-48cc-be69-df784664d3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.002961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1\n",
       "0           0  0.003640  0.002961\n",
       "1           1  0.000045  0.000039\n",
       "2           2  0.000116  0.000094\n",
       "3           3  0.000689  0.000550\n",
       "4           4  0.000313  0.000245"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('embed1.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc2554c-62ed-426d-b9cf-366f53c59c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Unnamed: 0'] = item[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f437d00b-3358-422e-9a99-0785b8d7113d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>take</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.002961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>taskforce</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>america</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>game</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>speak</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0         0         1\n",
       "0       take  0.003640  0.002961\n",
       "1  taskforce  0.000045  0.000039\n",
       "2    america  0.000116  0.000094\n",
       "3       game  0.000689  0.000550\n",
       "4      speak  0.000313  0.000245"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3b3e0c7-2eea-4c87-b037-38513b3cceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(item[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "771a30b4-1395-48a7-b872-a9722a5a00df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████▋                                                                 | 45171/385977 [03:57<29:38, 191.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 :   nan           node2 :learning machine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████▋                                                                | 50374/385977 [04:27<29:41, 188.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 :   nan           node2 :water blood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▏                                                              | 58470/385977 [05:13<28:16, 193.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 :   association           node2 :nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▎                                                           | 74795/385977 [06:45<27:45, 186.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 :   nan           node2 :cd44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████▍                                                          | 80305/385977 [07:16<26:36, 191.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 :   nan           node2 :prg4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████▍                                                | 129497/385977 [12:00<22:10, 192.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 :   hiv status           node2 :nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████████████████████████▍                       | 261163/385977 [24:16<12:09, 171.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 :   protein ubiquitination           node2 :nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████▏                     | 270849/385977 [25:12<11:38, 164.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 :   nan           node2 :case isolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████▏         | 333778/385977 [31:19<05:00, 173.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 :   evidence           node2 :nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 385977/385977 [36:33<00:00, 175.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_edges_name)\n",
    "df_train = df_train.replace(np.nan, 'nan', regex=True)\n",
    "list_real_labels = []\n",
    "list_pred_scores = []\n",
    "count = 0\n",
    "links = 0\n",
    "for i_row in tqdm(range(len(df_train.node1))): # for each training set data\n",
    "    node1 = df_train.node1[i_row]\n",
    "    node2 = df_train.node2[i_row]\n",
    "    #print(count)\n",
    "    count = count + 1\n",
    "    #print(f\"{node1}   {node2}\")\n",
    "    if(node1=='nan' or node2=='nan'):\n",
    "        print('node1 :   '+str(node1)+'           node2 :'+str(node2))\n",
    "        continue     \n",
    "    # Find all nbrs of node1 and node2 in training graph that overlap\n",
    "    #list_nbrs = sorted(nx.common_neighbors(G, node1, node2))\n",
    "\n",
    "    #total_sum = 0\n",
    "    # if list_nbrs isn't empty, find the weights of all the edges connected to the nbrs\n",
    "    #for i in range(len(list_nbrs)):\n",
    "    #   curr_weight = G.degree(list_nbrs[i], weight='weight')\n",
    "    #    total_sum += -1/np.log(curr_weight)\n",
    "\n",
    "    #\n",
    "    \n",
    "    a = data.loc[items.index(node1)][1]\n",
    "    #print (a)\n",
    "    b = data.loc[items.index(node2)][1]\n",
    "    #print (b)\n",
    "    c = data.loc[items.index(node1)][2]  \n",
    "    #print (c)\n",
    "    d = data.loc[items.index(node2)][2]\n",
    "    #print (d)\n",
    "    list_real_labels.append(df_train.labels[i_row])\n",
    "    list_pred_scores.append([a+b,c+d])\n",
    "    links +=1\n",
    "    \n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78de8241-ae0e-4cf8-bb82-0170f27ec731",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame(zip(list_pred_scores,list_real_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a52e164-acc7-4672-9729-e15395120023",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ec67e-06b5-4577-b81b-21be08085797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each training set data\n",
    "node1 = df_train.node1[:100]\n",
    "node2 = df_train.node2[:100]\n",
    "#print(count)\n",
    "count = count + 1\n",
    "print(f\"{node1}   {node2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51505626-bbc8-4b59-80ba-f88083d0eaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1598391903534312e-05\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[items.index(df_train.node1[9])][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e4b29-a51b-46d6-98ff-cc04b26bc619",
   "metadata": {},
   "source": [
    "<h1>data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13c5272-782e-48bc-9bf3-90ab98cf9f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.00356625739699922, 0.0027306399032904]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.0020819222243952506, 0.0007408251879191296]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.0006256529013015892, 0.0002373182085459]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[3.474998679482063e-06, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[3.95946301762555e-06, 1.4353060324953249e-06]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               0  1\n",
       "0           0       [0.00356625739699922, 0.0027306399032904]  1\n",
       "1           1  [0.0020819222243952506, 0.0007408251879191296]  1\n",
       "2           2     [0.0006256529013015892, 0.0002373182085459]  1\n",
       "3           3                    [3.474998679482063e-06, 0.0]  0\n",
       "4           4  [3.95946301762555e-06, 1.4353060324953249e-06]  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv(\"all_data.csv\")\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a89df9-71d7-4fa3-9c49-8498126df0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 385968/385968 [00:11<00:00, 34124.44it/s]\n"
     ]
    }
   ],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "for i in tqdm(range(len(x))):\n",
    "    x_data.append([float(x['0'][i].replace('[','').replace(']',\"\").split(',')[0]),float(x['0'][i].replace('[','').replace(']',\"\").split(',')[1])])\n",
    "    y_data.append(x['1'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdb118d4-718c-49f3-805f-1683bd65a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x_data, y_data, \n",
    "                                                test_size = 0.3, \n",
    "                                                random_state = 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb9d577-d9c1-478b-a21c-b52a6f6643b9",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression<\\h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c345f83-ed85-4422-963b-5ab6ab459014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "\n",
    "lr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed5ff4f1-3311-4c05-8be1-e631568ddc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = lr.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "801f0f20-82fa-4fc9-ba98-17ea2b4ee2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7815115164391014"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a484801-9fd0-4b34-973b-f0c9fb681325",
   "metadata": {},
   "source": [
    "<h1>lgbm<\\h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d2636-0054-41be-bc3d-1ec8517bb29d",
   "metadata": {},
   "source": [
    "[22]\tvalid_0's auc: 0.971098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5d5e5e5-c3ca-4a45-ad40-62dc39ffeacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 134822, number of negative: 135355\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 270177, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499014 -> initscore=-0.003946\n",
      "[LightGBM] [Info] Start training from score -0.003946\n",
      "[1]\tvalid_0's auc: 0.970811\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's auc: 0.970835\n",
      "[3]\tvalid_0's auc: 0.970865\n",
      "[4]\tvalid_0's auc: 0.970865\n",
      "[5]\tvalid_0's auc: 0.970927\n",
      "[6]\tvalid_0's auc: 0.970927\n",
      "[7]\tvalid_0's auc: 0.97093\n",
      "[8]\tvalid_0's auc: 0.970931\n",
      "[9]\tvalid_0's auc: 0.970931\n",
      "[10]\tvalid_0's auc: 0.970937\n",
      "[11]\tvalid_0's auc: 0.971056\n",
      "[12]\tvalid_0's auc: 0.971057\n",
      "[13]\tvalid_0's auc: 0.971056\n",
      "[14]\tvalid_0's auc: 0.971048\n",
      "[15]\tvalid_0's auc: 0.971047\n",
      "[16]\tvalid_0's auc: 0.971029\n",
      "[17]\tvalid_0's auc: 0.971029\n",
      "[18]\tvalid_0's auc: 0.971031\n",
      "[19]\tvalid_0's auc: 0.971049\n",
      "[20]\tvalid_0's auc: 0.971049\n",
      "[21]\tvalid_0's auc: 0.971075\n",
      "[22]\tvalid_0's auc: 0.971098\n",
      "[23]\tvalid_0's auc: 0.971054\n",
      "[24]\tvalid_0's auc: 0.971061\n",
      "[25]\tvalid_0's auc: 0.971054\n",
      "[26]\tvalid_0's auc: 0.971011\n",
      "[27]\tvalid_0's auc: 0.971019\n",
      "[28]\tvalid_0's auc: 0.971026\n",
      "[29]\tvalid_0's auc: 0.971024\n",
      "[30]\tvalid_0's auc: 0.97103\n",
      "[31]\tvalid_0's auc: 0.971027\n",
      "[32]\tvalid_0's auc: 0.971021\n",
      "[33]\tvalid_0's auc: 0.971028\n",
      "[34]\tvalid_0's auc: 0.971019\n",
      "[35]\tvalid_0's auc: 0.971018\n",
      "[36]\tvalid_0's auc: 0.971016\n",
      "[37]\tvalid_0's auc: 0.971007\n",
      "[38]\tvalid_0's auc: 0.971006\n",
      "[39]\tvalid_0's auc: 0.971001\n",
      "[40]\tvalid_0's auc: 0.970999\n",
      "[41]\tvalid_0's auc: 0.970984\n",
      "[42]\tvalid_0's auc: 0.970983\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.971098\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "train_data = lgbm.Dataset(xtrain, ytrain)\n",
    "test_data = lgbm.Dataset(xtest, ytest)\n",
    "\n",
    "# define parameters\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'num_threads' : 2,\n",
    "    'seed' : 76\n",
    "}\n",
    "\n",
    "# train lightGBM model\n",
    "model = lgbm.train(parameters,\n",
    "                   train_data,\n",
    "                   valid_sets=test_data,\n",
    "                   num_boost_round=1000,\n",
    "                   early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f4afe0-8471-4dff-8e19-105ef8145b68",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7996f0faa0b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlgbm_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlgbm_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphs\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphs\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graphs\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 93\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "lgbm_pred = model.predict(xtest, num_iteration=model.best_iteration)\n",
    "accuracy_score(ytest,lgbm_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61436e5f-0417-41f0-a804-972a34d2d4da",
   "metadata": {},
   "source": [
    "# Gaussian naive_bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bfa813a-c573-45c0-96fb-486f834b1981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8430bd0b-f7ed-44b2-9c06-a5c359e37b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.747683325992521"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "nb_pred = gnb.fit(xtrain, ytrain).predict(xtest)\n",
    "\n",
    "\n",
    "accuracy_score(ytest,nb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ed4cc6-a118-4589-b07d-68c7c0454c2a",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8fe70b-bfcb-4ffb-8219-c82a7e9a5271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f87fa3a9-1f42-469a-84eb-6ad95f8da2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "051d31a7-b9a9-4ae1-857c-9d011796e8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.917169728217219"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pred = clf.predict(xtest)\n",
    "accuracy_score(ytest,svm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea39f51-00d0-4ddf-b867-71047212fb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
