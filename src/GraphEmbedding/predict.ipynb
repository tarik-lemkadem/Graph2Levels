{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ed32f3-5b15-49eb-85af-b5b403127efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\tarik\\Anaconda3\\envs\\graphs\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "from Embed import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd81a30-8450-43a2-8e1f-e8169f364d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectAdarScores(G, train_edges_name):\n",
    "    \n",
    "    # find which edges are unconnected in the training\n",
    "    df_train = pd.read_csv(train_edges_name)\n",
    "    df_train = df_train.replace(np.nan, 'nan', regex=True)\n",
    "    #print(G.neighbors('nan'))\n",
    "    #print(err)\n",
    "    #list_unconnected = df_train.index[df_train['training_labels'] == 0].tolist() #df_train.where(df_train['training_labels']==0))\n",
    "\n",
    "    list_real_labels = []\n",
    "    list_pred_scores = []\n",
    "    count =0\n",
    "    for i_row in range(len(df_train.node1)): # for each training set data\n",
    "        node1 = df_train.node1[i_row]\n",
    "        node2 = df_train.node2[i_row]\n",
    "        print(count)\n",
    "        count = count + 1\n",
    "        if(node1=='nan' or node2=='nan'):\n",
    "            print('node1 :   '+str(node1)+'           node2 :'+str(node2))\n",
    "            continue     \n",
    "        # Find all nbrs of node1 and node2 in training graph that overlap\n",
    "        list_nbrs = sorted(nx.common_neighbors(G, node1, node2))\n",
    "            \n",
    "        total_sum = 0\n",
    "        # if list_nbrs isn't empty, find the weights of all the edges connected to the nbrs\n",
    "        for i in range(len(list_nbrs)):\n",
    "            curr_weight = G.degree(list_nbrs[i], weight='weight')\n",
    "            total_sum += -1/np.log(curr_weight)\n",
    "\n",
    "        #\n",
    "        list_real_labels.append(df_train.labels[i_row])\n",
    "        list_pred_scores.append(total_sum)\n",
    "\n",
    "    return list_pred_scores, list_real_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd9884-d001-4912-a1bb-05e956ec3a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(np.array(list_pred_scores_train).reshape(-1, 1),list_real_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9cf49-17ae-44ea-96de-583aaa4d9354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
